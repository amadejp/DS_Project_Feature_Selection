{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature evaluation testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rank_eval_pipeline as rep\n",
    "from helper_functions import get_true_baseline, area_under_the_curve, corrected_performance_time_metric\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_ranking(features, scores, avg_exec_time=np.inf):\n",
    "    RE = rep.RankEval(\"\",\"\")\n",
    "    RE.ranking = features\n",
    "    RE.scores = scores\n",
    "    RE.evaluate_ranking()\n",
    "    t = 0\n",
    "\n",
    "    baseline = get_true_baseline()\n",
    "\n",
    "    auc_first_gen = np.mean(RE.eval_res_first_gen[0] - baseline)/(1 - area_under_the_curve(baseline))\n",
    "    auc_singles = np.mean(RE.eval_res_singles[0] - baseline)/(1 - area_under_the_curve(baseline))\n",
    "\n",
    "    return {\"auc_first_gen\": auc_first_gen, \"auc_singles\": auc_singles, \"exec_time\": t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "\n",
    "def average_ranking(rankings, times):\n",
    "    \"\"\"\n",
    "    Using the borda count method, average the rankings in the list of rankings\n",
    "    \"\"\"\n",
    "    scores = defaultdict(int)\n",
    "    for ranking in rankings:\n",
    "        for i, feature in enumerate(ranking):\n",
    "            scores[feature] += len(ranking) - i\n",
    "\n",
    "    # sort by score, highest first\n",
    "    average_ranking = sorted(scores.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "    # extract the features and their scores from the (feature, score) pairs\n",
    "    average_features = [feature for feature, score in average_ranking]\n",
    "    average_scores = [score for feature, score in average_ranking]\n",
    "    average_time = np.mean(times)\n",
    "\n",
    "    return average_features, average_scores, average_time\n",
    "\n",
    "def read_ranking(filename):\n",
    "    with open(filename) as f:\n",
    "        ranking = json.load(f)\n",
    "    return ranking[\"results\"][\"features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_file_lists(subsample_proportions, directory, hash='all'):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of lists of files for each subsampling proportion.\n",
    "\n",
    "    If subsample_\n",
    "\n",
    "    \"\"\"\n",
    "    # initialize dictionary to subsample_proportions as keys and empty lists as values\n",
    "    files = {subsample_proportion: [] for subsample_proportion in subsample_proportions}\n",
    "    \n",
    "    all_files = os.listdir(directory)\n",
    "    for subsample_proportion in subsample_proportions:\n",
    "        for file in all_files:\n",
    "            if (f\"sub{subsample_proportion}_\" in file and f\"features-{hash}\" in file):\n",
    "                files[subsample_proportion].append(directory + file)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of ensemble ranking:  {'auc_first_gen': 0.5214661177060711, 'auc_singles': 0.14547636923520285, 'exec_time': 0}\n",
      "Performance of total dataset ranking:  {'auc_first_gen': 0.47056990830295586, 'auc_singles': 0.12423395028042686, 'exec_time': 276.79150891304016}\n"
     ]
    }
   ],
   "source": [
    "rf_list = get_file_lists([0.1], \"results/random_forest_0.1_batch/\")\n",
    "rf_list = rf_list[0.1]\n",
    "rf_list = [read_ranking(file) for file in rf_list]\n",
    "# this is an ensemble of all sub 0.1 random forest rankings\n",
    "RF_ensemble_ranking = average_ranking(rf_list)\n",
    "result1 = evaluate_ranking(RF_ensemble_ranking[0], RF_ensemble_ranking[1])\n",
    "# this is the ranking for the total dataset\n",
    "resutlt2 = corrected_performance_time_metric('results/random_forest_score_seed0_sub1.0_features-all.json')\n",
    "print(\"Performance of ensemble ranking: \", result1)\n",
    "print(\"Performance of total dataset ranking: \", resutlt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of ensemble ranking:  {'auc_first_gen': 0.5017874133348473, 'auc_singles': 0.14984106673748165, 'exec_time': 0}\n",
      "Performance of total dataset ranking:  {'auc_first_gen': 0.47056990830295586, 'auc_singles': 0.12423395028042686, 'exec_time': 276.79150891304016}\n"
     ]
    }
   ],
   "source": [
    "rf_list = get_file_lists([0.01], \"results/random_forest_0.01_batch/\")\n",
    "rf_list = rf_list[0.01]\n",
    "rf_list = [read_ranking(file) for file in rf_list]\n",
    "# this is an ensemble of all sub 0.01 random forest rankings\n",
    "RF_ensemble_ranking = average_ranking(rf_list)\n",
    "result1 = evaluate_ranking(RF_ensemble_ranking[0], RF_ensemble_ranking[1])\n",
    "# this is the ranking for the total dataset\n",
    "resutlt2 = corrected_performance_time_metric('results/random_forest_score_seed0_sub1.0_features-all.json')\n",
    "print(\"Performance of ensemble ranking: \", result1)\n",
    "print(\"Performance of total dataset ranking: \", resutlt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of ensemble ranking:  {'auc_first_gen': 0.47949814892709847, 'auc_singles': 0.14195247239119385, 'exec_time': 0}\n",
      "Performance of total dataset ranking:  {'auc_first_gen': 0.47056990830295586, 'auc_singles': 0.12423395028042686, 'exec_time': 276.79150891304016}\n"
     ]
    }
   ],
   "source": [
    "rf_list = get_file_lists([0.001], \"results/random_forest_optimization/\")\n",
    "rf_list = rf_list[0.001]\n",
    "rf_list = [read_ranking(file) for file in rf_list]\n",
    "# this is an ensemble of all sub 0.001 random forest rankings\n",
    "RF_ensemble_ranking = average_ranking(rf_list)\n",
    "result1 = evaluate_ranking(RF_ensemble_ranking[0], RF_ensemble_ranking[1])\n",
    "# this is the ranking for the total dataset\n",
    "resutlt2 = corrected_performance_time_metric('results/random_forest_score_seed0_sub1.0_features-all.json')\n",
    "print(\"Performance of ensemble ranking: \", result1)\n",
    "print(\"Performance of total dataset ranking: \", resutlt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of ensemble ranking for 0.001 subsampling: \n",
      " {'auc_first_gen': 0.47949814892709847, 'auc_singles': 0.14195247239119385, 'exec_time': 0}\n",
      "Performance of total dataset ranking: \n",
      " {'auc_first_gen': 0.47056990830295586, 'auc_singles': 0.12423395028042686, 'exec_time': 276.79150891304016}\n"
     ]
    }
   ],
   "source": [
    "subsampling = 0.001\n",
    "rf_list = get_file_lists([subsampling], \"results/random_forest_optimization/\")\n",
    "rf_list = rf_list[subsampling]\n",
    "rf_list = [read_ranking(file) for file in rf_list]\n",
    "# this is an ensemble of all sub 0.001 random forest rankings\n",
    "RF_ensemble_ranking = average_ranking(rf_list)\n",
    "result1 = evaluate_ranking(RF_ensemble_ranking[0], RF_ensemble_ranking[1])\n",
    "# this is the ranking for the total dataset\n",
    "resutlt2 = corrected_performance_time_metric('results/random_forest_score_seed0_sub1.0_features-all.json')\n",
    "print(f\"Performance of ensemble ranking for {subsampling} subsampling: \\n\", result1)\n",
    "print(\"Performance of total dataset ranking: \\n\", resutlt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of ensemble ranking for 0.0004 subsampling: \n",
      " {'auc_first_gen': 0.4687214436628085, 'auc_singles': 0.14498408132936036, 'exec_time': 0}\n",
      "Performance of total dataset ranking: \n",
      " {'auc_first_gen': 0.47056990830295586, 'auc_singles': 0.12423395028042686, 'exec_time': 276.79150891304016}\n"
     ]
    }
   ],
   "source": [
    "subsampling = 0.0004\n",
    "rf_list = get_file_lists([subsampling], \"results/random_forest_optimization/\")\n",
    "rf_list = rf_list[subsampling]\n",
    "rf_list = [read_ranking(file) for file in rf_list]\n",
    "# this is an ensemble of all sub 0.0001 random forest rankings\n",
    "RF_ensemble_ranking = average_ranking(rf_list)\n",
    "result1 = evaluate_ranking(RF_ensemble_ranking[0], RF_ensemble_ranking[1])\n",
    "# this is the ranking for the total dataset\n",
    "resutlt2 = corrected_performance_time_metric('results/random_forest_score_seed0_sub1.0_features-all.json')\n",
    "print(f\"Performance of ensemble ranking for {subsampling} subsampling: \\n\", result1)\n",
    "print(\"Performance of total dataset ranking: \\n\", resutlt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature98',\n",
       " 'feature99',\n",
       " 'feature88',\n",
       " 'feature89',\n",
       " 'feature84',\n",
       " 'feature87',\n",
       " 'feature86',\n",
       " 'feature83',\n",
       " 'feature85',\n",
       " 'feature23',\n",
       " 'feature82',\n",
       " 'feature22',\n",
       " 'feature81',\n",
       " 'feature5',\n",
       " 'feature49',\n",
       " 'feature48',\n",
       " 'feature32',\n",
       " 'feature56',\n",
       " 'feature1',\n",
       " 'feature90',\n",
       " 'feature39',\n",
       " 'feature91',\n",
       " 'feature71',\n",
       " 'feature15',\n",
       " 'feature2',\n",
       " 'feature12',\n",
       " 'feature10',\n",
       " 'feature3',\n",
       " 'feature33',\n",
       " 'feature50',\n",
       " 'feature36',\n",
       " 'feature21',\n",
       " 'feature55',\n",
       " 'feature0',\n",
       " 'feature18',\n",
       " 'feature37',\n",
       " 'feature62',\n",
       " 'feature59',\n",
       " 'feature57',\n",
       " 'feature42',\n",
       " 'feature17',\n",
       " 'feature8',\n",
       " 'feature40',\n",
       " 'feature60',\n",
       " 'feature9',\n",
       " 'feature51',\n",
       " 'feature19',\n",
       " 'feature20',\n",
       " 'feature14',\n",
       " 'feature58',\n",
       " 'feature27',\n",
       " 'feature7',\n",
       " 'feature44',\n",
       " 'feature26',\n",
       " 'feature67',\n",
       " 'feature52',\n",
       " 'feature47',\n",
       " 'feature16',\n",
       " 'feature29',\n",
       " 'feature4',\n",
       " 'feature30',\n",
       " 'feature11',\n",
       " 'feature46',\n",
       " 'feature64',\n",
       " 'feature41',\n",
       " 'feature66',\n",
       " 'feature43',\n",
       " 'feature28',\n",
       " 'feature38',\n",
       " 'feature69',\n",
       " 'feature54',\n",
       " 'feature53',\n",
       " 'feature63',\n",
       " 'feature68',\n",
       " 'feature35',\n",
       " 'feature24',\n",
       " 'feature61',\n",
       " 'feature31',\n",
       " 'feature25',\n",
       " 'feature45',\n",
       " 'feature65',\n",
       " 'feature34',\n",
       " 'feature13',\n",
       " 'feature72',\n",
       " 'feature6',\n",
       " 'feature73',\n",
       " 'feature80',\n",
       " 'feature77',\n",
       " 'feature76',\n",
       " 'feature70',\n",
       " 'feature74',\n",
       " 'feature75',\n",
       " 'feature78',\n",
       " 'feature79',\n",
       " 'feature92',\n",
       " 'feature93',\n",
       " 'feature94',\n",
       " 'feature95',\n",
       " 'feature96',\n",
       " 'feature97']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_ranking = read_ranking()\n",
    "ran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_ranking = read_ranking('results/xgboost_score_seed0_sub1.0_features-all.json')\n",
    "\n",
    "pearson_correlation_ranking = read_ranking('results/pearson_correlation_score_seed0_sub1.0_features-all.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ranking = average_ranking([random_forest_ranking, pearson_correlation_ranking])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc_first_gen': 0.4600267567954295,\n",
       " 'auc_singles': 0.08264037262534994,\n",
       " 'exec_time': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_ranking(new_ranking[0], new_ranking[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc_first_gen': 0.39817829102262176,\n",
       " 'auc_singles': 0.048860216981625515,\n",
       " 'exec_time': 2.2313971519470215}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_performance_time_metric(\"results/pearson_correlation_score_seed0_sub1.0_features-all.json\", shuffle_correction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc_first_gen': 0.47056990830295586,\n",
       " 'auc_singles': 0.12423395028042686,\n",
       " 'exec_time': 276.79150891304016}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_performance_time_metric('results/random_forest_score_seed0_sub1.0_features-all.json', shuffle_correction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc_first_gen': 0.09015312352184,\n",
       " 'auc_singles': 0.04834261482073889,\n",
       " 'exec_time': 33.497220277786255}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_performance_time_metric('results/xgboost_score_seed0_sub1.0_features-all.json', shuffle_correction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/full_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2224352179, 1066182028, 3103603272, 3770660814,  429120973,\n",
       "        553222847, 3552167677, 3071463162, 2282816406, 1625990768,\n",
       "       4286417659, 3750766477, 2733500236, 1622987352, 1145370728,\n",
       "       3898133265,  928562214, 1343824683, 2386995490, 2882519864,\n",
       "       2360873032, 1709828517,  645747896, 1928497154,  152192149,\n",
       "       1408821955, 1258086162, 2469287282, 4041503919, 3899963624,\n",
       "       3259400523, 2106730950, 1675661237,  108838858,  413545197,\n",
       "       4294832690, 1243073278], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out details about feature23\n",
    "data['feature23'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "full_data = pd.read_csv('data/full_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0000000e+00, 9.4202566e-09, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 1.3453784e-07, 7.5021042e-08, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 9.9999982e-01, 0.0000000e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = full_data.sample(frac=0.1, random_state=0)\n",
    "X, y = full_data.drop([\"info_click_valid\"], axis=1), full_data['info_click_valid']\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(X, y)\n",
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature0    -0.026055\n",
      "feature1    -0.035900\n",
      "feature2    -0.014218\n",
      "feature3     0.022289\n",
      "feature4    -0.033770\n",
      "               ...   \n",
      "feature95         NaN\n",
      "feature96         NaN\n",
      "feature97         NaN\n",
      "feature98    1.000000\n",
      "feature99   -1.000000\n",
      "Length: 100, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X, y = full_data.drop([\"info_click_valid\"], axis=1), full_data['info_click_valid']\n",
    "correlations = X.apply(lambda x: x.corr(y))\n",
    "correlations.sort_values(ascending=False)\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = full_data.sample(frac=0.1, random_state=0)\n",
    "data = data.drop(['feature99',\"feature98\"], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(['info_click_valid'], axis=1), data['info_click_valid'], test_size=0.2, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3773439756674521\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_test)\n",
    "print(log_loss(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43197243402039104\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_test)\n",
    "print(log_loss(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2, 0.2, 0.2, ..., 0.2, 0.2, 0.2])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1988247022337397"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(full_data[\"info_click_valid\"])/len(full_data[\"info_click_valid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.3862943611198906"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(0.2/0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature23 0.38630625195049645\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m temp_features\u001b[39m.\u001b[39mappend(feature)\n\u001b[0;32m     12\u001b[0m model \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBClassifier()\n\u001b[1;32m---> 13\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train_copy[temp_features], y_train)\n\u001b[0;32m     14\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict_proba(X_test_copy[temp_features])[:, \u001b[39m1\u001b[39m]  \u001b[39m# Get probability estimates\u001b[39;00m\n\u001b[0;32m     15\u001b[0m score \u001b[39m=\u001b[39m log_loss(y_test, predictions)\n",
      "File \u001b[1;32mc:\\Users\\Leon\\anaconda3\\envs\\ds_project\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Leon\\anaconda3\\envs\\ds_project\\lib\\site-packages\\xgboost\\sklearn.py:1490\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1462\u001b[0m (\n\u001b[0;32m   1463\u001b[0m     model,\n\u001b[0;32m   1464\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1470\u001b[0m )\n\u001b[0;32m   1471\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1472\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[0;32m   1473\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1487\u001b[0m     feature_types\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_types,\n\u001b[0;32m   1488\u001b[0m )\n\u001b[1;32m-> 1490\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m   1491\u001b[0m     params,\n\u001b[0;32m   1492\u001b[0m     train_dmatrix,\n\u001b[0;32m   1493\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[0;32m   1494\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[0;32m   1495\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[0;32m   1496\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[0;32m   1497\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[0;32m   1498\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[0;32m   1499\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   1500\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m   1501\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1502\u001b[0m )\n\u001b[0;32m   1504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[0;32m   1505\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Leon\\anaconda3\\envs\\ds_project\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Leon\\anaconda3\\envs\\ds_project\\lib\\site-packages\\xgboost\\training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[0;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Leon\\anaconda3\\envs\\ds_project\\lib\\site-packages\\xgboost\\core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[0;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[0;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[0;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_features = []\n",
    "X_train_copy = X_train.copy()\n",
    "X_test_copy = X_test.copy()\n",
    "\n",
    "for i in range(len(X_train.columns)):\n",
    "    best_score = np.inf  # Initialize to infinity\n",
    "    best_feature = None\n",
    "    for feature in X_train_copy.columns:\n",
    "        if feature not in best_features:  # Only consider features not yet in best_features\n",
    "            temp_features = best_features.copy()\n",
    "            temp_features.append(feature)\n",
    "            model = xgb.XGBClassifier()\n",
    "            model.fit(X_train_copy[temp_features], y_train)\n",
    "            predictions = model.predict_proba(X_test_copy[temp_features])[:, 1]  # Get probability estimates\n",
    "            score = log_loss(y_test, predictions)\n",
    "            if score < best_score:  # Change comparison to less than\n",
    "                best_score = score\n",
    "                best_feature = feature\n",
    "    best_features.append(best_feature)\n",
    "    print(best_feature, best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m temp_features\u001b[39m.\u001b[39mappend(feature)\n\u001b[0;32m     12\u001b[0m model \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBClassifier()\n\u001b[1;32m---> 13\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train_copy[temp_features], y_train)\n\u001b[0;32m     14\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict_proba(X_test_copy[temp_features])[:, \u001b[39m1\u001b[39m]  \u001b[39m# Get probability estimates\u001b[39;00m\n\u001b[0;32m     15\u001b[0m score \u001b[39m=\u001b[39m log_loss(y_test, predictions)\n",
      "File \u001b[1;32mc:\\Users\\Leon\\anaconda3\\envs\\ds_project\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Leon\\anaconda3\\envs\\ds_project\\lib\\site-packages\\xgboost\\sklearn.py:1490\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1462\u001b[0m (\n\u001b[0;32m   1463\u001b[0m     model,\n\u001b[0;32m   1464\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1470\u001b[0m )\n\u001b[0;32m   1471\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1472\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[0;32m   1473\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1487\u001b[0m     feature_types\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_types,\n\u001b[0;32m   1488\u001b[0m )\n\u001b[1;32m-> 1490\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m   1491\u001b[0m     params,\n\u001b[0;32m   1492\u001b[0m     train_dmatrix,\n\u001b[0;32m   1493\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[0;32m   1494\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[0;32m   1495\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[0;32m   1496\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[0;32m   1497\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[0;32m   1498\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[0;32m   1499\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   1500\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m   1501\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1502\u001b[0m )\n\u001b[0;32m   1504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[0;32m   1505\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Leon\\anaconda3\\envs\\ds_project\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Leon\\anaconda3\\envs\\ds_project\\lib\\site-packages\\xgboost\\training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[0;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Leon\\anaconda3\\envs\\ds_project\\lib\\site-packages\\xgboost\\core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[0;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[0;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[0;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_features = []\n",
    "X_train_copy = X_train.copy()\n",
    "X_test_copy = X_test.copy()\n",
    "\n",
    "for i in range(len(X_train.columns)):\n",
    "    best_score = np.inf  # Initialize to infinity\n",
    "    best_feature = None\n",
    "    for feature in X_train_copy.columns:\n",
    "        if feature not in best_features:  # Only consider features not yet in best_features\n",
    "            temp_features = best_features.copy()\n",
    "            temp_features.append(feature)\n",
    "            model = xgb.XGBClassifier()\n",
    "            model.fit(X_train_copy[temp_features], y_train)\n",
    "            predictions = model.predict_proba(X_test_copy[temp_features])[:, 1]  # Get probability estimates\n",
    "            score = log_loss(y_test, predictions)\n",
    "            if score < best_score:  # Change comparison to less than\n",
    "                best_score = score\n",
    "                best_feature = feature\n",
    "    best_features.append(best_feature)\n",
    "    print(best_feature, best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_eval_pipeline import RankEval\n",
    "import rank_algos\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/full_data.csv')\n",
    "# # subsample the data\n",
    "# data = data.sample(frac=0.01, random_state=42)\n",
    "data = data.drop(columns=['feature98', 'feature99'])\n",
    "# subsample the data\n",
    "data = data.sample(frac=0.001, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data.drop(\"info_click_valid\", axis=1), data[\"info_click_valid\"]\n",
    "\n",
    "# make stratified split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply xgboost on training data\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba_pred = model.predict_proba(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model performance on 0.1% of the dataset (without features 98,99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.59%\n",
      "Logloss: 3.72\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "logloss = log_loss(y_test, [i[0] for i in y_proba_pred])\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print(\"Logloss: %.2f\" % (logloss))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model performance on entire dataset (without features 98,99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.16%\n",
      "Logloss: 2.09\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "logloss = log_loss(y_test, [i[0] for i in y_proba_pred])\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print(\"Logloss: %.2f\" % (logloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0067364 , 0.00763135, 0.00293042, 0.00312282, 0.06042694,\n",
       "       0.04295708, 0.00168319, 0.00422322, 0.00311172, 0.00438067,\n",
       "       0.00343244, 0.00571202, 0.00384746, 0.00536718, 0.07457934,\n",
       "       0.00502488, 0.01268342, 0.00725955, 0.00482081, 0.0035692 ,\n",
       "       0.00490443, 0.00314804, 0.00687523, 0.2657493 , 0.0026869 ,\n",
       "       0.00228163, 0.00745443, 0.00318208, 0.00269152, 0.0021485 ,\n",
       "       0.00198203, 0.00624343, 0.04997206, 0.00205908, 0.00262307,\n",
       "       0.00297043, 0.00245738, 0.00285267, 0.00240105, 0.00234927,\n",
       "       0.00257787, 0.00364806, 0.0026798 , 0.01090775, 0.00363707,\n",
       "       0.00425268, 0.00335931, 0.00242065, 0.02436822, 0.00337768,\n",
       "       0.00247684, 0.0028435 , 0.0025859 , 0.00254479, 0.00354356,\n",
       "       0.00226208, 0.01080691, 0.0021332 , 0.00211958, 0.00252539,\n",
       "       0.00216155, 0.00319993, 0.02726843, 0.00379415, 0.00245245,\n",
       "       0.00216157, 0.00243531, 0.00232389, 0.00241675, 0.00752994,\n",
       "       0.        , 0.00589758, 0.00314215, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.04746434, 0.01137729, 0.04604642, 0.01190613,\n",
       "       0.01116765, 0.01811673, 0.01257447, 0.00636166, 0.02648426,\n",
       "       0.00383287, 0.00428111, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>info_click_valid</th>\n",
       "      <th>feature0</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>...</th>\n",
       "      <th>feature90</th>\n",
       "      <th>feature91</th>\n",
       "      <th>feature92</th>\n",
       "      <th>feature93</th>\n",
       "      <th>feature94</th>\n",
       "      <th>feature95</th>\n",
       "      <th>feature96</th>\n",
       "      <th>feature97</th>\n",
       "      <th>feature98</th>\n",
       "      <th>feature99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3282490636</td>\n",
       "      <td>3723861767</td>\n",
       "      <td>592628169</td>\n",
       "      <td>2093237750</td>\n",
       "      <td>3617548381</td>\n",
       "      <td>2965721776</td>\n",
       "      <td>3543218850</td>\n",
       "      <td>1072184752</td>\n",
       "      <td>1418147852</td>\n",
       "      <td>...</td>\n",
       "      <td>3637550824</td>\n",
       "      <td>3790689556</td>\n",
       "      <td>2087688982</td>\n",
       "      <td>3899436442</td>\n",
       "      <td>3255798468</td>\n",
       "      <td>355094504</td>\n",
       "      <td>3479975775</td>\n",
       "      <td>3411024218</td>\n",
       "      <td>3656293508</td>\n",
       "      <td>2846559631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2736633149</td>\n",
       "      <td>3188050045</td>\n",
       "      <td>3599848058</td>\n",
       "      <td>2300041243</td>\n",
       "      <td>3503728323</td>\n",
       "      <td>1531702445</td>\n",
       "      <td>3543218850</td>\n",
       "      <td>2634671414</td>\n",
       "      <td>2266512440</td>\n",
       "      <td>...</td>\n",
       "      <td>3637550824</td>\n",
       "      <td>3790689556</td>\n",
       "      <td>2087688982</td>\n",
       "      <td>3899436442</td>\n",
       "      <td>3255798468</td>\n",
       "      <td>355094504</td>\n",
       "      <td>3479975775</td>\n",
       "      <td>3411024218</td>\n",
       "      <td>3656293508</td>\n",
       "      <td>2846559631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1067402948</td>\n",
       "      <td>108565582</td>\n",
       "      <td>2502341442</td>\n",
       "      <td>3474641266</td>\n",
       "      <td>3503728323</td>\n",
       "      <td>1531702445</td>\n",
       "      <td>3543218850</td>\n",
       "      <td>4108477053</td>\n",
       "      <td>870407079</td>\n",
       "      <td>...</td>\n",
       "      <td>147472623</td>\n",
       "      <td>3508206064</td>\n",
       "      <td>2087688982</td>\n",
       "      <td>3899436442</td>\n",
       "      <td>3255798468</td>\n",
       "      <td>355094504</td>\n",
       "      <td>3479975775</td>\n",
       "      <td>3411024218</td>\n",
       "      <td>3656293508</td>\n",
       "      <td>2846559631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3634365896</td>\n",
       "      <td>2567512859</td>\n",
       "      <td>753387811</td>\n",
       "      <td>2124887610</td>\n",
       "      <td>3503728323</td>\n",
       "      <td>2965721776</td>\n",
       "      <td>3543218850</td>\n",
       "      <td>4108477053</td>\n",
       "      <td>3981694603</td>\n",
       "      <td>...</td>\n",
       "      <td>147472623</td>\n",
       "      <td>3508206064</td>\n",
       "      <td>2087688982</td>\n",
       "      <td>3899436442</td>\n",
       "      <td>3255798468</td>\n",
       "      <td>355094504</td>\n",
       "      <td>3479975775</td>\n",
       "      <td>3411024218</td>\n",
       "      <td>3656293508</td>\n",
       "      <td>2846559631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3282490636</td>\n",
       "      <td>1241498584</td>\n",
       "      <td>99521842</td>\n",
       "      <td>868270843</td>\n",
       "      <td>3503728323</td>\n",
       "      <td>1531702445</td>\n",
       "      <td>3543218850</td>\n",
       "      <td>4108477053</td>\n",
       "      <td>3377404711</td>\n",
       "      <td>...</td>\n",
       "      <td>147472623</td>\n",
       "      <td>2450605253</td>\n",
       "      <td>2087688982</td>\n",
       "      <td>3899436442</td>\n",
       "      <td>3255798468</td>\n",
       "      <td>355094504</td>\n",
       "      <td>3479975775</td>\n",
       "      <td>3411024218</td>\n",
       "      <td>3656293508</td>\n",
       "      <td>2846559631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   info_click_valid    feature0    feature1    feature2    feature3  \\\n",
       "0                 1  3282490636  3723861767   592628169  2093237750   \n",
       "1                 1  2736633149  3188050045  3599848058  2300041243   \n",
       "2                 1  1067402948   108565582  2502341442  3474641266   \n",
       "3                 1  3634365896  2567512859   753387811  2124887610   \n",
       "4                 1  3282490636  1241498584    99521842   868270843   \n",
       "\n",
       "     feature4    feature5    feature6    feature7    feature8  ...  \\\n",
       "0  3617548381  2965721776  3543218850  1072184752  1418147852  ...   \n",
       "1  3503728323  1531702445  3543218850  2634671414  2266512440  ...   \n",
       "2  3503728323  1531702445  3543218850  4108477053   870407079  ...   \n",
       "3  3503728323  2965721776  3543218850  4108477053  3981694603  ...   \n",
       "4  3503728323  1531702445  3543218850  4108477053  3377404711  ...   \n",
       "\n",
       "    feature90   feature91   feature92   feature93   feature94  feature95  \\\n",
       "0  3637550824  3790689556  2087688982  3899436442  3255798468  355094504   \n",
       "1  3637550824  3790689556  2087688982  3899436442  3255798468  355094504   \n",
       "2   147472623  3508206064  2087688982  3899436442  3255798468  355094504   \n",
       "3   147472623  3508206064  2087688982  3899436442  3255798468  355094504   \n",
       "4   147472623  2450605253  2087688982  3899436442  3255798468  355094504   \n",
       "\n",
       "    feature96   feature97   feature98   feature99  \n",
       "0  3479975775  3411024218  3656293508  2846559631  \n",
       "1  3479975775  3411024218  3656293508  2846559631  \n",
       "2  3479975775  3411024218  3656293508  2846559631  \n",
       "3  3479975775  3411024218  3656293508  2846559631  \n",
       "4  3479975775  3411024218  3656293508  2846559631  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reliefF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE = RankEval(data, rank_method=rank_algos.ReliefF_score, seed=0, subsampling_proportion=subsampling)\n",
    "RE.get_scores()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SURF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE = RankEval(data, rank_method=rank_algos.SURF_score, seed=0, subsampling_proportion=subsampling)\n",
    "RE.get_scores()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SURF*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE = RankEval(data, rank_method=rank_algos.SURFstar_score, seed=0, subsampling_proportion=subsampling)\n",
    "RE.get_scores()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiSURF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE = RankEval(data, rank_method=rank_algos.MultiSURF_score, seed=0, subsampling_proportion=subsampling)\n",
    "RE.get_scores()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiSURFstar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE = RankEval(data, rank_method=rank_algos.MultiSURFstar_score, seed=0, subsampling_proportion=subsampling)\n",
    "RE.get_scores()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reliefE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE = RankEval(data, rank_method=rank_algos.ReliefE_score, seed=0, subsampling_proportion=subsampling)\n",
    "RE.get_scores()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE = RankEval(data, rank_method=rank_algos.xgboost_score, seed=0, subsampling_proportion=subsampling)\n",
    "RE.get_scores()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE = RankEval(data, rank_method=rank_algos.random_forest_score, seed=0, subsampling_proportion=subsampling)\n",
    "RE.get_scores()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE = RankEval(data, rank_method=rank_algos.chi2_score, seed=0, subsampling_proportion=subsampling)\n",
    "RE.get_scores()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation Importance\n",
    "Problem is we need to build a model, which means choosing a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perm_model = RandomForestClassifier()\n",
    "# perm_model.fit(X, y)\n",
    "# perm_results = permutation_importance(perm_model, X, y, n_repeats=5, random_state=0, n_jobs=-1)\n",
    "# perm_results[\"importances_mean\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_ranker = LinearRegression()\n",
    "# lr_ranker.fit(X, y)\n",
    "# lr_results = {i:score for i, score in enumerate(lr_ranker.coef_)}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
